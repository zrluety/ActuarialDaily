{
  "hash": "fa9a5e75dc7ad6967c575bde69c5c4fc",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Seasonality in Loss Development Triangles\"\ndescription: \"How to handle seasonality in loss development triangles\"\nauthor: \"Zachary Luety\"\ndate: \"11/8/2024\"\ndraft: true\n---\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(ChainLadder))\nlibrary(gt)\n```\n:::\n\n\n# Problem statement\n\nIn this post we introduce the impact of seasonality on loss development factors.\n\n# Data\n\nFirst we will create simulated loss data. This loss data wil include seasonal effects where losses in calendar quarter vary by calendar quarter.\n\nEach origination period should have identical ultimate losses, however, as we will see, the seasonal effects within our data distorts the our development factors resulting in incorrect ultimate loss estimates.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloss <- tibble(\n    origin = c(rep(1, 8), rep(2, 7), rep(3, 6), rep(4, 5), rep(5, 4), rep(6, 3), rep(7, 2), rep(8, 1)),\n    development = c(1:8,1:7,1:6,1:5,1:4,1:3,1:2,1)\n)\n\nloss <- loss |> mutate(\n    calPeriod = origin + development - 1,\n    calQuarter = ifelse((origin + development - 1) %% 4 == 0, 4, (origin + development - 1) %% 4),\n    lossAmt = case_when(\n        calQuarter == 1 ~ 100,\n        calQuarter %in% c(2, 3) ~ 50,\n        calQuarter == 4 ~ 40\n    )\n)\n```\n:::\n\n\nNow we use the `ChainLadder` package to create a development triangle from our loss data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a triangle\ntriangle <- as.triangle(loss, origin = \"origin\", dev = \"development\", value = \"lossAmt\")\ntriangle\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      development\norigin   1   2   3   4   5  6  7  8\n     1 100  50  50  40 100 50 50 40\n     2  50  50  40 100  50 50 40 NA\n     3  50  40 100  50  50 40 NA NA\n     4  40 100  50  50  40 NA NA NA\n     5 100  50  50  40  NA NA NA NA\n     6  50  50  40  NA  NA NA NA NA\n     7  50  40  NA  NA  NA NA NA NA\n     8  40  NA  NA  NA  NA NA NA NA\n```\n\n\n:::\n\n```{.r .cell-code}\n# Make a cumulative triangle\ncumTriangle <- incr2cum(triangle)\ncumTriangle\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      development\norigin   1   2   3   4   5   6   7   8\n     1 100 150 200 240 340 390 440 480\n     2  50 100 140 240 290 340 380  NA\n     3  50  90 190 240 290 330  NA  NA\n     4  40 140 190 240 280  NA  NA  NA\n     5 100 150 200 240  NA  NA  NA  NA\n     6  50 100 140  NA  NA  NA  NA  NA\n     7  50  90  NA  NA  NA  NA  NA  NA\n     8  40  NA  NA  NA  NA  NA  NA  NA\n```\n\n\n:::\n\n```{.r .cell-code}\n# Show age-to-age factor\nata(cumTriangle)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      development\norigin   1-2   2-3   3-4   4-5   5-6   6-7   7-8\n  1    1.500 1.333 1.200 1.417 1.147 1.128 1.091\n  2    2.000 1.400 1.714 1.208 1.172 1.118    NA\n  3    1.800 2.111 1.263 1.208 1.138    NA    NA\n  4    3.500 1.357 1.263 1.167    NA    NA    NA\n  5    1.500 1.333 1.200    NA    NA    NA    NA\n  6    2.000 1.400    NA    NA    NA    NA    NA\n  7    1.800    NA    NA    NA    NA    NA    NA\n  smpl 2.014 1.489 1.328 1.250 1.152 1.123 1.091\n  vwtd 1.864 1.452 1.304 1.250 1.152 1.123 1.091\n```\n\n\n:::\n\n```{.r .cell-code}\n# Create a Chainladder model\nCL <- chainladder(cumTriangle)\n\n# Create runoff triangle\npredict(CL)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      dev\norigin   1         2        3        4        5        6        7        8\n     1 100 150.00000 200.0000 240.0000 340.0000 390.0000 440.0000 480.0000\n     2  50 100.00000 140.0000 240.0000 290.0000 340.0000 380.0000 414.5455\n     3  50  90.00000 190.0000 240.0000 290.0000 330.0000 370.6849 404.3836\n     4  40 140.00000 190.0000 240.0000 280.0000 322.6087 362.3824 395.3262\n     5 100 150.00000 200.0000 240.0000 300.0000 345.6522 388.2668 423.5638\n     6  50 100.00000 140.0000 182.6087 228.2609 262.9962 295.4204 322.2768\n     7  50  90.00000 130.6849 170.4586 213.0733 245.4974 275.7643 300.8337\n     8  40  74.54545 108.2441 141.1879 176.4849 203.3413 228.4108 249.1754\n```\n\n\n:::\n:::\n\n\nWhile we would expect each policy period to ultimate have the same 480 ultimate loss, seasonality distorts the loss development factors and leads to incorrect ultimates.\n\n# Correcting for seasonality\n\nNow that we understand the problem, how do we fix it? We will start with an exerpt from the excellent Forecasting: Principles and Practice\n\n<blockquote>\n... variation seen in seasonal data may be due to simple calendar effects. In such cases, it is usually much easier to remove the variation before doing any further analysis. \n<br><br>\nFor example, if you are studying the total monthly sales in a retail store, there will be variation between the months simply because of the different numbers of trading days in each month, in addition to the seasonal variation across the year. It is easy to remove this variation by computing average sales per trading day in each month, rather than total sales in the month. Then we effectively remove the calendar variation.\n</blockquote>\n\nWhile we are not working with sales data, we can use this principle to eliminate the seasonal effects within our loss data removing the variation between quarters prior to developing our losses.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbyQtr <- loss |>\n    filter(development <= 4) |> # focus on first 4 quarters\n    pivot_wider(id_cols = origin, names_from = calQuarter, values_from = lossAmt) |> # pivot table by quarter\n    drop_na() %>% # complete year only\n    mutate(\n        yearTotal = rowSums(across(`1`: `4`)),\n        expectedPerQtr = yearTotal / 4,\n        across(`1`:`4`, ~ .x / expectedPerQtr)\n    ) |>\n    summarize(across(`1`:`4`, mean))\n\nseasonal_factors <- tibble(\n    calQuarter = as.integer(names(byQtr)),\n    relativity = as.vector(t(byQtr))\n)\nseasonal_factors\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 2\n  calQuarter relativity\n       <int>      <dbl>\n1          1      1.67 \n2          2      0.833\n3          3      0.833\n4          4      0.667\n```\n\n\n:::\n:::\n\n\nNow we can bring in our relativity factors and create an adjusted loss amount and develop to ultimate.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadj_triangle <- loss |>\n    inner_join(seasonal_factors, by = \"calQuarter\") |>\n    mutate(\n        lossAmtAdj = lossAmt / relativity\n    ) |>\n        as.triangle(origin = \"origin\", dev = \"development\", value = \"lossAmtAdj\")\nadj_triangle\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      development\norigin  1  2  3  4  5  6  7  8\n     1 60 60 60 60 60 60 60 60\n     2 60 60 60 60 60 60 60 NA\n     3 60 60 60 60 60 60 NA NA\n     4 60 60 60 60 60 NA NA NA\n     5 60 60 60 60 NA NA NA NA\n     6 60 60 60 NA NA NA NA NA\n     7 60 60 NA NA NA NA NA NA\n     8 60 NA NA NA NA NA NA NA\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Make a cumulative triangle\ncum_adj_triangle <- incr2cum(adj_triangle)\ncum_adj_triangle\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      development\norigin  1   2   3   4   5   6   7   8\n     1 60 120 180 240 300 360 420 480\n     2 60 120 180 240 300 360 420  NA\n     3 60 120 180 240 300 360  NA  NA\n     4 60 120 180 240 300  NA  NA  NA\n     5 60 120 180 240  NA  NA  NA  NA\n     6 60 120 180  NA  NA  NA  NA  NA\n     7 60 120  NA  NA  NA  NA  NA  NA\n     8 60  NA  NA  NA  NA  NA  NA  NA\n```\n\n\n:::\n\n```{.r .cell-code}\n# Create a Chainladder model\nCL_adj <- chainladder(cum_adj_triangle)\n\n# Create runoff triangle\nult_triangle <- predict(CL_adj)\nult_triangle\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      dev\norigin  1   2   3   4   5   6   7   8\n     1 60 120 180 240 300 360 420 480\n     2 60 120 180 240 300 360 420 480\n     3 60 120 180 240 300 360 420 480\n     4 60 120 180 240 300 360 420 480\n     5 60 120 180 240 300 360 420 480\n     6 60 120 180 240 300 360 420 480\n     7 60 120 180 240 300 360 420 480\n     8 60 120 180 240 300 360 420 480\n```\n\n\n:::\n:::\n\n\n# Converting back to unadjusted values\n\nIf we actually care about the true loss emergence pattern, we need to return to an unadjusted loss amount. To do that, we back out the seasonal adjustment on our predictions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# convert triangle to incremental\ninc_tri <- cum2incr(ult_triangle)\n\n# add fields necessary to join\nforecast <- inc_tri |>\n    as.data.frame() |> # convert to long form\n    as_tibble() |>\n    rename(development = dev, lossAmt = value) |>\n    mutate(\n        origin = as.integer(origin),\n        calPeriod = origin + development - 1,\n        calQuarter = ifelse((origin + development - 1) %% 4 == 0, 4, (origin + development - 1) %% 4)\n    ) |>\n    filter(calPeriod > 8) |>\n    inner_join(seasonal_factors, by = \"calQuarter\") |>\n    mutate(\n        lossAmt = lossAmt * relativity\n    ) |>\n    as_tibble() |>\n    select(origin, development, calPeriod, calQuarter, lossAmt)\nforecast\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 28 × 5\n   origin development calPeriod calQuarter lossAmt\n    <int>       <dbl>     <dbl>      <dbl>   <dbl>\n 1      8           2         9          1   100. \n 2      7           3         9          1   100  \n 3      8           3        10          2    50  \n 4      6           4         9          1   100  \n 5      7           4        10          2    50  \n 6      8           4        11          3    50  \n 7      5           5         9          1   100. \n 8      6           5        10          2    50.0\n 9      7           5        11          3    50.0\n10      8           5        12          4    40.0\n# ℹ 18 more rows\n```\n\n\n:::\n:::\n\n\nFinally, we can bring combine our original data and our forecast, display as a fully developed triangle and check our results.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nultimate_loss <- union(loss, forecast) |>\n    pivot_wider(id_cols = origin, names_from = development, values_from = lossAmt)\n\nultimate_loss_mat <- ultimate_loss |>\n    select(`1`:`8`) |>\n    as.matrix()\n\nrownames(ultimate_loss_mat) <- ultimate_loss$origin\nnames(dimnames(ultimate_loss_mat)) <- c(\"origin\", \"dev\")\nultimate_loss_mat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      dev\norigin   1   2   3   4   5   6   7   8\n     1 100  50  50  40 100  50  50  40\n     2  50  50  40 100  50  50  40 100\n     3  50  40 100  50  50  40 100  50\n     4  40 100  50  50  40 100  50  50\n     5 100  50  50  40 100  50  50  40\n     6  50  50  40 100  50  50  40 100\n     7  50  40 100  50  50  40 100  50\n     8  40 100  50  50  40 100  50  50\n```\n\n\n:::\n:::\n\n\nNow we can see we are estimating the appropriate ultimate loss amount while maintaining seasonal variability.\n\nIn a future post, we will continue explore the effects of seasonality when other distortions exists, such as policy year trends.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}