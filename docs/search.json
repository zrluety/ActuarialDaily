[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/seasonally-adjusted-triangles/index.html",
    "href": "posts/seasonally-adjusted-triangles/index.html",
    "title": "Seasonality in Loss Development Triangles",
    "section": "",
    "text": "Code\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(ChainLadder))\nlibrary(gt)\n\n\n\nProblem statement\nIn this post we introduce the impact of seasonality on loss development factors.\n\n\nData\nFirst we will create simulated loss data. This loss data wil include seasonal effects where losses in calendar quarter vary by calendar quarter.\nEach origination period should have identical ultimate losses, however, as we will see, the seasonal effects within our data distorts the our development factors resulting in incorrect ultimate loss estimates.\n\nloss &lt;- tibble(\n    origin = c(rep(1, 8), rep(2, 7), rep(3, 6), rep(4, 5), rep(5, 4), rep(6, 3), rep(7, 2), rep(8, 1)),\n    development = c(1:8,1:7,1:6,1:5,1:4,1:3,1:2,1)\n)\n\nloss &lt;- loss |&gt; mutate(\n    calPeriod = origin + development - 1,\n    calQuarter = ifelse((origin + development - 1) %% 4 == 0, 4, (origin + development - 1) %% 4),\n    lossAmt = case_when(\n        calQuarter == 1 ~ 100,\n        calQuarter %in% c(2, 3) ~ 50,\n        calQuarter == 4 ~ 40\n    )\n)\n\nNow we use the ChainLadder package to create a development triangle from our loss data.\n\n# Create a triangle\ntriangle &lt;- as.triangle(loss, origin = \"origin\", dev = \"development\", value = \"lossAmt\")\ntriangle\n\n      development\norigin   1   2   3   4   5  6  7  8\n     1 100  50  50  40 100 50 50 40\n     2  50  50  40 100  50 50 40 NA\n     3  50  40 100  50  50 40 NA NA\n     4  40 100  50  50  40 NA NA NA\n     5 100  50  50  40  NA NA NA NA\n     6  50  50  40  NA  NA NA NA NA\n     7  50  40  NA  NA  NA NA NA NA\n     8  40  NA  NA  NA  NA NA NA NA\n\n# Make a cumulative triangle\ncumTriangle &lt;- incr2cum(triangle)\ncumTriangle\n\n      development\norigin   1   2   3   4   5   6   7   8\n     1 100 150 200 240 340 390 440 480\n     2  50 100 140 240 290 340 380  NA\n     3  50  90 190 240 290 330  NA  NA\n     4  40 140 190 240 280  NA  NA  NA\n     5 100 150 200 240  NA  NA  NA  NA\n     6  50 100 140  NA  NA  NA  NA  NA\n     7  50  90  NA  NA  NA  NA  NA  NA\n     8  40  NA  NA  NA  NA  NA  NA  NA\n\n# Show age-to-age factor\nata(cumTriangle)\n\n      development\norigin   1-2   2-3   3-4   4-5   5-6   6-7   7-8\n  1    1.500 1.333 1.200 1.417 1.147 1.128 1.091\n  2    2.000 1.400 1.714 1.208 1.172 1.118    NA\n  3    1.800 2.111 1.263 1.208 1.138    NA    NA\n  4    3.500 1.357 1.263 1.167    NA    NA    NA\n  5    1.500 1.333 1.200    NA    NA    NA    NA\n  6    2.000 1.400    NA    NA    NA    NA    NA\n  7    1.800    NA    NA    NA    NA    NA    NA\n  smpl 2.014 1.489 1.328 1.250 1.152 1.123 1.091\n  vwtd 1.864 1.452 1.304 1.250 1.152 1.123 1.091\n\n# Create a Chainladder model\nCL &lt;- chainladder(cumTriangle)\n\n# Create runoff triangle\npredict(CL)\n\n      dev\norigin   1         2        3        4        5        6        7        8\n     1 100 150.00000 200.0000 240.0000 340.0000 390.0000 440.0000 480.0000\n     2  50 100.00000 140.0000 240.0000 290.0000 340.0000 380.0000 414.5455\n     3  50  90.00000 190.0000 240.0000 290.0000 330.0000 370.6849 404.3836\n     4  40 140.00000 190.0000 240.0000 280.0000 322.6087 362.3824 395.3262\n     5 100 150.00000 200.0000 240.0000 300.0000 345.6522 388.2668 423.5638\n     6  50 100.00000 140.0000 182.6087 228.2609 262.9962 295.4204 322.2768\n     7  50  90.00000 130.6849 170.4586 213.0733 245.4974 275.7643 300.8337\n     8  40  74.54545 108.2441 141.1879 176.4849 203.3413 228.4108 249.1754\n\n\nWhile we would expect each policy period to ultimate have the same 480 ultimate loss, seasonality distorts the loss development factors and leads to incorrect ultimates.\n\n\nCorrecting for seasonality\nNow that we understand the problem, how do we fix it? We will start with an exerpt from the excellent Forecasting: Principles and Practice\n\n… variation seen in seasonal data may be due to simple calendar effects. In such cases, it is usually much easier to remove the variation before doing any further analysis.  For example, if you are studying the total monthly sales in a retail store, there will be variation between the months simply because of the different numbers of trading days in each month, in addition to the seasonal variation across the year. It is easy to remove this variation by computing average sales per trading day in each month, rather than total sales in the month. Then we effectively remove the calendar variation.\n\nWhile we are not working with sales data, we can use this principle to eliminate the seasonal effects within our loss data removing the variation between quarters prior to developing our losses.\n\nbyQtr &lt;- loss |&gt;\n    filter(development &lt;= 4) |&gt; # focus on first 4 quarters\n    pivot_wider(id_cols = origin, names_from = calQuarter, values_from = lossAmt) |&gt; # pivot table by quarter\n    drop_na() %&gt;% # complete year only\n    mutate(\n        yearTotal = rowSums(across(`1`: `4`)),\n        expectedPerQtr = yearTotal / 4,\n        across(`1`:`4`, ~ .x / expectedPerQtr)\n    ) |&gt;\n    summarize(across(`1`:`4`, mean))\n\nseasonal_factors &lt;- tibble(\n    calQuarter = as.integer(names(byQtr)),\n    relativity = as.vector(t(byQtr))\n)\nseasonal_factors\n\n# A tibble: 4 × 2\n  calQuarter relativity\n       &lt;int&gt;      &lt;dbl&gt;\n1          1      1.67 \n2          2      0.833\n3          3      0.833\n4          4      0.667\n\n\nNow we can bring in our relativity factors and create an adjusted loss amount and develop to ultimate.\n\nadj_triangle &lt;- loss |&gt;\n    inner_join(seasonal_factors, by = \"calQuarter\") |&gt;\n    mutate(\n        lossAmtAdj = lossAmt / relativity\n    ) |&gt;\n        as.triangle(origin = \"origin\", dev = \"development\", value = \"lossAmtAdj\")\nadj_triangle\n\n      development\norigin  1  2  3  4  5  6  7  8\n     1 60 60 60 60 60 60 60 60\n     2 60 60 60 60 60 60 60 NA\n     3 60 60 60 60 60 60 NA NA\n     4 60 60 60 60 60 NA NA NA\n     5 60 60 60 60 NA NA NA NA\n     6 60 60 60 NA NA NA NA NA\n     7 60 60 NA NA NA NA NA NA\n     8 60 NA NA NA NA NA NA NA\n\n\n\n# Make a cumulative triangle\ncum_adj_triangle &lt;- incr2cum(adj_triangle)\ncum_adj_triangle\n\n      development\norigin  1   2   3   4   5   6   7   8\n     1 60 120 180 240 300 360 420 480\n     2 60 120 180 240 300 360 420  NA\n     3 60 120 180 240 300 360  NA  NA\n     4 60 120 180 240 300  NA  NA  NA\n     5 60 120 180 240  NA  NA  NA  NA\n     6 60 120 180  NA  NA  NA  NA  NA\n     7 60 120  NA  NA  NA  NA  NA  NA\n     8 60  NA  NA  NA  NA  NA  NA  NA\n\n# Create a Chainladder model\nCL_adj &lt;- chainladder(cum_adj_triangle)\n\n# Create runoff triangle\nult_triangle &lt;- predict(CL_adj)\nult_triangle\n\n      dev\norigin  1   2   3   4   5   6   7   8\n     1 60 120 180 240 300 360 420 480\n     2 60 120 180 240 300 360 420 480\n     3 60 120 180 240 300 360 420 480\n     4 60 120 180 240 300 360 420 480\n     5 60 120 180 240 300 360 420 480\n     6 60 120 180 240 300 360 420 480\n     7 60 120 180 240 300 360 420 480\n     8 60 120 180 240 300 360 420 480\n\n\n\n\nConverting back to unadjusted values\nIf we actually care about the true loss emergence pattern, we need to return to an unadjusted loss amount. To do that, we back out the seasonal adjustment on our predictions.\n\n# convert triangle to incremental\ninc_tri &lt;- cum2incr(ult_triangle)\n\n# add fields necessary to join\nforecast &lt;- inc_tri |&gt;\n    as.data.frame() |&gt; # convert to long form\n    as_tibble() |&gt;\n    rename(development = dev, lossAmt = value) |&gt;\n    mutate(\n        origin = as.integer(origin),\n        calPeriod = origin + development - 1,\n        calQuarter = ifelse((origin + development - 1) %% 4 == 0, 4, (origin + development - 1) %% 4)\n    ) |&gt;\n    filter(calPeriod &gt; 8) |&gt;\n    inner_join(seasonal_factors, by = \"calQuarter\") |&gt;\n    mutate(\n        lossAmt = lossAmt * relativity\n    ) |&gt;\n    as_tibble() |&gt;\n    select(origin, development, calPeriod, calQuarter, lossAmt)\nforecast\n\n# A tibble: 28 × 5\n   origin development calPeriod calQuarter lossAmt\n    &lt;int&gt;       &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;\n 1      8           2         9          1   100. \n 2      7           3         9          1   100  \n 3      8           3        10          2    50  \n 4      6           4         9          1   100  \n 5      7           4        10          2    50  \n 6      8           4        11          3    50  \n 7      5           5         9          1   100. \n 8      6           5        10          2    50.0\n 9      7           5        11          3    50.0\n10      8           5        12          4    40.0\n# ℹ 18 more rows\n\n\nFinally, we can bring combine our original data and our forecast, display as a fully developed triangle and check our results.\n\nultimate_loss &lt;- union(loss, forecast) |&gt;\n    pivot_wider(id_cols = origin, names_from = development, values_from = lossAmt)\n\nultimate_loss_mat &lt;- ultimate_loss |&gt;\n    select(`1`:`8`) |&gt;\n    as.matrix()\n\nrownames(ultimate_loss_mat) &lt;- ultimate_loss$origin\nnames(dimnames(ultimate_loss_mat)) &lt;- c(\"origin\", \"dev\")\nultimate_loss_mat\n\n      dev\norigin   1   2   3   4   5   6   7   8\n     1 100  50  50  40 100  50  50  40\n     2  50  50  40 100  50  50  40 100\n     3  50  40 100  50  50  40 100  50\n     4  40 100  50  50  40 100  50  50\n     5 100  50  50  40 100  50  50  40\n     6  50  50  40 100  50  50  40 100\n     7  50  40 100  50  50  40 100  50\n     8  40 100  50  50  40 100  50  50\n\n\nNow we can see we are estimating the appropriate ultimate loss amount while maintaining seasonal variability.\nIn a future post, we will continue explore the effects of seasonality when other distortions exists, such as policy year trends."
  },
  {
    "objectID": "posts/making-triangles/index.html",
    "href": "posts/making-triangles/index.html",
    "title": "Modern Tooling to Create Development Triangles",
    "section": "",
    "text": "In this post we’ll look at 3 ways to create a loss development triangle using Pandas, Polars, and DuckDB.\n\nimport os\nfrom pathlib import Path\n\nimport duckdb\nimport pandas as pd\nimport polars as pl\n\nFor this post, we will use the PP Auto Dataset available on the CAS website.\n\ndata_filepath = 'https://www.casact.org/sites/default/files/2021-04/ppauto_pos.csv'\n\n\n\n\ndata = (\n    pd.read_csv(data_filepath)\n    .query(\"GRCODE == 43 and DevelopmentYear &lt;= 1997\") # filter to single insurer and exclude the bottom right of the development triangle\n)\ndata.head()\n\n\n\n\n\n\n\n\n\nGRCODE\nGRNAME\nAccidentYear\nDevelopmentYear\nDevelopmentLag\nIncurLoss_B\nCumPaidLoss_B\nBulkLoss_B\nEarnedPremDIR_B\nEarnedPremCeded_B\nEarnedPremNet_B\nSingle\nPostedReserve97_B\n\n\n\n\n0\n43\nIDS Property Cas Ins Co\n1988\n1988\n1\n607\n133\n226\n957\n62\n895\n0\n73044\n\n\n1\n43\nIDS Property Cas Ins Co\n1988\n1989\n2\n647\n333\n129\n957\n62\n895\n0\n73044\n\n\n2\n43\nIDS Property Cas Ins Co\n1988\n1990\n3\n582\n431\n38\n957\n62\n895\n0\n73044\n\n\n3\n43\nIDS Property Cas Ins Co\n1988\n1991\n4\n598\n570\n19\n957\n62\n895\n0\n73044\n\n\n4\n43\nIDS Property Cas Ins Co\n1988\n1992\n5\n614\n615\n0\n957\n62\n895\n0\n73044\n\n\n\n\n\n\n\n\nTo create the triangle we use the pivot_table method.\n\ndata.pivot(\n    values=\"CumPaidLoss_B\",\n    index=\"AccidentYear\",\n    columns=\"DevelopmentLag\",\n)\n\n\n\n\n\n\n\n\nDevelopmentLag\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nAccidentYear\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1988\n133.0\n333.0\n431.0\n570.0\n615.0\n615.0\n615.0\n614.0\n614.0\n614.0\n\n\n1989\n934.0\n1746.0\n2365.0\n2579.0\n2763.0\n2966.0\n2940.0\n2978.0\n2978.0\nNaN\n\n\n1990\n2030.0\n4864.0\n6880.0\n8087.0\n8595.0\n8743.0\n8763.0\n8762.0\nNaN\nNaN\n\n\n1991\n4537.0\n11527.0\n15123.0\n16656.0\n17321.0\n18076.0\n18308.0\nNaN\nNaN\nNaN\n\n\n1992\n7564.0\n16061.0\n22465.0\n25204.0\n26517.0\n27124.0\nNaN\nNaN\nNaN\nNaN\n\n\n1993\n8343.0\n19900.0\n26732.0\n30079.0\n31249.0\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1994\n12565.0\n26922.0\n33867.0\n38338.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1995\n13437.0\n26012.0\n31677.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1996\n12604.0\n23446.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1997\n12292.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\n\n\n\n\ndata = (\n    pl.read_csv(data_filepath)\n    .filter((pl.col(\"GRCODE\") == 43) & (pl.col(\"DevelopmentYear\") &lt;= 1997))\n)\n\ndata\n\n\n\nshape: (55, 13)\n\n\n\nGRCODE\nGRNAME\nAccidentYear\nDevelopmentYear\nDevelopmentLag\nIncurLoss_B\nCumPaidLoss_B\nBulkLoss_B\nEarnedPremDIR_B\nEarnedPremCeded_B\nEarnedPremNet_B\nSingle\nPostedReserve97_B\n\n\ni64\nstr\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\n\n\n\n\n43\n\"IDS Property Cas Ins Co\"\n1988\n1988\n1\n607\n133\n226\n957\n62\n895\n0\n73044\n\n\n43\n\"IDS Property Cas Ins Co\"\n1988\n1989\n2\n647\n333\n129\n957\n62\n895\n0\n73044\n\n\n43\n\"IDS Property Cas Ins Co\"\n1988\n1990\n3\n582\n431\n38\n957\n62\n895\n0\n73044\n\n\n43\n\"IDS Property Cas Ins Co\"\n1988\n1991\n4\n598\n570\n19\n957\n62\n895\n0\n73044\n\n\n43\n\"IDS Property Cas Ins Co\"\n1988\n1992\n5\n614\n615\n0\n957\n62\n895\n0\n73044\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n43\n\"IDS Property Cas Ins Co\"\n1995\n1996\n2\n43705\n26012\n9166\n51512\n3883\n47629\n0\n73044\n\n\n43\n\"IDS Property Cas Ins Co\"\n1995\n1997\n3\n42909\n31677\n6571\n51512\n3883\n47629\n0\n73044\n\n\n43\n\"IDS Property Cas Ins Co\"\n1996\n1996\n1\n41837\n12604\n16780\n52481\n5552\n46929\n0\n73044\n\n\n43\n\"IDS Property Cas Ins Co\"\n1996\n1997\n2\n41304\n23446\n10786\n52481\n5552\n46929\n0\n73044\n\n\n43\n\"IDS Property Cas Ins Co\"\n1997\n1997\n1\n44436\n12292\n17959\n56978\n5133\n51845\n0\n73044\n\n\n\n\n\n\n\n\ndata.filter(\n    (pl.col(\"GRCODE\") == 43) & (pl.col(\"DevelopmentYear\") &lt;= 1997)\n).pivot(\n    on=\"DevelopmentLag\",\n    index=\"AccidentYear\",\n    values=\"CumPaidLoss_B\"\n)\n\n\n\nshape: (10, 11)\n\n\n\nAccidentYear\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\n\n\n\n\n1988\n133\n333\n431\n570\n615\n615\n615\n614\n614\n614\n\n\n1989\n934\n1746\n2365\n2579\n2763\n2966\n2940\n2978\n2978\nnull\n\n\n1990\n2030\n4864\n6880\n8087\n8595\n8743\n8763\n8762\nnull\nnull\n\n\n1991\n4537\n11527\n15123\n16656\n17321\n18076\n18308\nnull\nnull\nnull\n\n\n1992\n7564\n16061\n22465\n25204\n26517\n27124\nnull\nnull\nnull\nnull\n\n\n1993\n8343\n19900\n26732\n30079\n31249\nnull\nnull\nnull\nnull\nnull\n\n\n1994\n12565\n26922\n33867\n38338\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n1995\n13437\n26012\n31677\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n1996\n12604\n23446\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n1997\n12292\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\n\n\n\n\n\n\n\n\nduckdb.sql(f\"\"\"\\\nCREATE TABLE data AS\n    SELECT * FROM read_csv('{data_filepath}') WHERE GRCODE = 43 AND DevelopmentYear &lt;= 1997;\n\"\"\")\n\n\nduckdb.sql(\"\"\"\\\n    PIVOT data\n    ON DevelopmentLag\n    USING SUM(CumPaidLoss_B)\n    GROUP BY AccidentYear\n    ORDER BY AccidentYear\n\"\"\")\n\n┌──────────────┬────────┬────────┬────────┬────────┬────────┬────────┬────────┬────────┬────────┬────────┐\n│ AccidentYear │   1    │   10   │   2    │   3    │   4    │   5    │   6    │   7    │   8    │   9    │\n│    int64     │ int128 │ int128 │ int128 │ int128 │ int128 │ int128 │ int128 │ int128 │ int128 │ int128 │\n├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n│         1988 │    133 │    614 │    333 │    431 │    570 │    615 │    615 │    615 │    614 │    614 │\n│         1989 │    934 │   NULL │   1746 │   2365 │   2579 │   2763 │   2966 │   2940 │   2978 │   2978 │\n│         1990 │   2030 │   NULL │   4864 │   6880 │   8087 │   8595 │   8743 │   8763 │   8762 │   NULL │\n│         1991 │   4537 │   NULL │  11527 │  15123 │  16656 │  17321 │  18076 │  18308 │   NULL │   NULL │\n│         1992 │   7564 │   NULL │  16061 │  22465 │  25204 │  26517 │  27124 │   NULL │   NULL │   NULL │\n│         1993 │   8343 │   NULL │  19900 │  26732 │  30079 │  31249 │   NULL │   NULL │   NULL │   NULL │\n│         1994 │  12565 │   NULL │  26922 │  33867 │  38338 │   NULL │   NULL │   NULL │   NULL │   NULL │\n│         1995 │  13437 │   NULL │  26012 │  31677 │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │\n│         1996 │  12604 │   NULL │  23446 │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │\n│         1997 │  12292 │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │\n├──────────────┴────────┴────────┴────────┴────────┴────────┴────────┴────────┴────────┴────────┴────────┤\n│ 10 rows                                                                                     11 columns │\n└────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n\n\nUnfortunately, this orders columns as strings so DevelopmentLag 10 comes before DevelopmentLag2. One workaround for this is to left pad (lpad) the DevelopmentLag prior to pivoting so the columns sort as expected.\n\nduckdb.sql(\n    \"\"\"\n    WITH cte\n    AS\n    (\n        SELECT * REPLACE (lpad(CAST(DevelopmentLag AS VARCHAR),2,'0')) AS DevelopmentLag\n        FROM data\n        WHERE GRCODE == 43\n        AND DevelopmentYear &lt;= 1997\n    )\n    PIVOT cte\n    ON DevelopmentLag\n    USING SUM(CumPaidLoss_B)\n    GROUP BY AccidentYear\n    ORDER BY AccidentYear\n    \"\"\"\n)\n\n┌──────────────┬────────┬────────┬────────┬────────┬────────┬────────┬────────┬────────┬────────┬────────┐\n│ AccidentYear │   01   │   02   │   03   │   04   │   05   │   06   │   07   │   08   │   09   │   10   │\n│    int64     │ int128 │ int128 │ int128 │ int128 │ int128 │ int128 │ int128 │ int128 │ int128 │ int128 │\n├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n│         1988 │    133 │    333 │    431 │    570 │    615 │    615 │    615 │    614 │    614 │    614 │\n│         1989 │    934 │   1746 │   2365 │   2579 │   2763 │   2966 │   2940 │   2978 │   2978 │   NULL │\n│         1990 │   2030 │   4864 │   6880 │   8087 │   8595 │   8743 │   8763 │   8762 │   NULL │   NULL │\n│         1991 │   4537 │  11527 │  15123 │  16656 │  17321 │  18076 │  18308 │   NULL │   NULL │   NULL │\n│         1992 │   7564 │  16061 │  22465 │  25204 │  26517 │  27124 │   NULL │   NULL │   NULL │   NULL │\n│         1993 │   8343 │  19900 │  26732 │  30079 │  31249 │   NULL │   NULL │   NULL │   NULL │   NULL │\n│         1994 │  12565 │  26922 │  33867 │  38338 │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │\n│         1995 │  13437 │  26012 │  31677 │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │\n│         1996 │  12604 │  23446 │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │\n│         1997 │  12292 │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │\n├──────────────┴────────┴────────┴────────┴────────┴────────┴────────┴────────┴────────┴────────┴────────┤\n│ 10 rows                                                                                     11 columns │\n└────────────────────────────────────────────────────────────────────────────────────────────────────────┘"
  },
  {
    "objectID": "posts/making-triangles/index.html#pandas",
    "href": "posts/making-triangles/index.html#pandas",
    "title": "Modern Tooling to Create Development Triangles",
    "section": "",
    "text": "data = (\n    pd.read_csv(data_filepath)\n    .query(\"GRCODE == 43 and DevelopmentYear &lt;= 1997\") # filter to single insurer and exclude the bottom right of the development triangle\n)\ndata.head()\n\n\n\n\n\n\n\n\n\nGRCODE\nGRNAME\nAccidentYear\nDevelopmentYear\nDevelopmentLag\nIncurLoss_B\nCumPaidLoss_B\nBulkLoss_B\nEarnedPremDIR_B\nEarnedPremCeded_B\nEarnedPremNet_B\nSingle\nPostedReserve97_B\n\n\n\n\n0\n43\nIDS Property Cas Ins Co\n1988\n1988\n1\n607\n133\n226\n957\n62\n895\n0\n73044\n\n\n1\n43\nIDS Property Cas Ins Co\n1988\n1989\n2\n647\n333\n129\n957\n62\n895\n0\n73044\n\n\n2\n43\nIDS Property Cas Ins Co\n1988\n1990\n3\n582\n431\n38\n957\n62\n895\n0\n73044\n\n\n3\n43\nIDS Property Cas Ins Co\n1988\n1991\n4\n598\n570\n19\n957\n62\n895\n0\n73044\n\n\n4\n43\nIDS Property Cas Ins Co\n1988\n1992\n5\n614\n615\n0\n957\n62\n895\n0\n73044\n\n\n\n\n\n\n\n\nTo create the triangle we use the pivot_table method.\n\ndata.pivot(\n    values=\"CumPaidLoss_B\",\n    index=\"AccidentYear\",\n    columns=\"DevelopmentLag\",\n)\n\n\n\n\n\n\n\n\nDevelopmentLag\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nAccidentYear\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1988\n133.0\n333.0\n431.0\n570.0\n615.0\n615.0\n615.0\n614.0\n614.0\n614.0\n\n\n1989\n934.0\n1746.0\n2365.0\n2579.0\n2763.0\n2966.0\n2940.0\n2978.0\n2978.0\nNaN\n\n\n1990\n2030.0\n4864.0\n6880.0\n8087.0\n8595.0\n8743.0\n8763.0\n8762.0\nNaN\nNaN\n\n\n1991\n4537.0\n11527.0\n15123.0\n16656.0\n17321.0\n18076.0\n18308.0\nNaN\nNaN\nNaN\n\n\n1992\n7564.0\n16061.0\n22465.0\n25204.0\n26517.0\n27124.0\nNaN\nNaN\nNaN\nNaN\n\n\n1993\n8343.0\n19900.0\n26732.0\n30079.0\n31249.0\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1994\n12565.0\n26922.0\n33867.0\n38338.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1995\n13437.0\n26012.0\n31677.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1996\n12604.0\n23446.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1997\n12292.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN"
  },
  {
    "objectID": "posts/making-triangles/index.html#polars",
    "href": "posts/making-triangles/index.html#polars",
    "title": "Modern Tooling to Create Development Triangles",
    "section": "",
    "text": "data = (\n    pl.read_csv(data_filepath)\n    .filter((pl.col(\"GRCODE\") == 43) & (pl.col(\"DevelopmentYear\") &lt;= 1997))\n)\n\ndata\n\n\n\nshape: (55, 13)\n\n\n\nGRCODE\nGRNAME\nAccidentYear\nDevelopmentYear\nDevelopmentLag\nIncurLoss_B\nCumPaidLoss_B\nBulkLoss_B\nEarnedPremDIR_B\nEarnedPremCeded_B\nEarnedPremNet_B\nSingle\nPostedReserve97_B\n\n\ni64\nstr\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\n\n\n\n\n43\n\"IDS Property Cas Ins Co\"\n1988\n1988\n1\n607\n133\n226\n957\n62\n895\n0\n73044\n\n\n43\n\"IDS Property Cas Ins Co\"\n1988\n1989\n2\n647\n333\n129\n957\n62\n895\n0\n73044\n\n\n43\n\"IDS Property Cas Ins Co\"\n1988\n1990\n3\n582\n431\n38\n957\n62\n895\n0\n73044\n\n\n43\n\"IDS Property Cas Ins Co\"\n1988\n1991\n4\n598\n570\n19\n957\n62\n895\n0\n73044\n\n\n43\n\"IDS Property Cas Ins Co\"\n1988\n1992\n5\n614\n615\n0\n957\n62\n895\n0\n73044\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n43\n\"IDS Property Cas Ins Co\"\n1995\n1996\n2\n43705\n26012\n9166\n51512\n3883\n47629\n0\n73044\n\n\n43\n\"IDS Property Cas Ins Co\"\n1995\n1997\n3\n42909\n31677\n6571\n51512\n3883\n47629\n0\n73044\n\n\n43\n\"IDS Property Cas Ins Co\"\n1996\n1996\n1\n41837\n12604\n16780\n52481\n5552\n46929\n0\n73044\n\n\n43\n\"IDS Property Cas Ins Co\"\n1996\n1997\n2\n41304\n23446\n10786\n52481\n5552\n46929\n0\n73044\n\n\n43\n\"IDS Property Cas Ins Co\"\n1997\n1997\n1\n44436\n12292\n17959\n56978\n5133\n51845\n0\n73044\n\n\n\n\n\n\n\n\ndata.filter(\n    (pl.col(\"GRCODE\") == 43) & (pl.col(\"DevelopmentYear\") &lt;= 1997)\n).pivot(\n    on=\"DevelopmentLag\",\n    index=\"AccidentYear\",\n    values=\"CumPaidLoss_B\"\n)\n\n\n\nshape: (10, 11)\n\n\n\nAccidentYear\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\n\n\n\n\n1988\n133\n333\n431\n570\n615\n615\n615\n614\n614\n614\n\n\n1989\n934\n1746\n2365\n2579\n2763\n2966\n2940\n2978\n2978\nnull\n\n\n1990\n2030\n4864\n6880\n8087\n8595\n8743\n8763\n8762\nnull\nnull\n\n\n1991\n4537\n11527\n15123\n16656\n17321\n18076\n18308\nnull\nnull\nnull\n\n\n1992\n7564\n16061\n22465\n25204\n26517\n27124\nnull\nnull\nnull\nnull\n\n\n1993\n8343\n19900\n26732\n30079\n31249\nnull\nnull\nnull\nnull\nnull\n\n\n1994\n12565\n26922\n33867\n38338\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n1995\n13437\n26012\n31677\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n1996\n12604\n23446\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n1997\n12292\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull"
  },
  {
    "objectID": "posts/making-triangles/index.html#duckdb",
    "href": "posts/making-triangles/index.html#duckdb",
    "title": "Modern Tooling to Create Development Triangles",
    "section": "",
    "text": "duckdb.sql(f\"\"\"\\\nCREATE TABLE data AS\n    SELECT * FROM read_csv('{data_filepath}') WHERE GRCODE = 43 AND DevelopmentYear &lt;= 1997;\n\"\"\")\n\n\nduckdb.sql(\"\"\"\\\n    PIVOT data\n    ON DevelopmentLag\n    USING SUM(CumPaidLoss_B)\n    GROUP BY AccidentYear\n    ORDER BY AccidentYear\n\"\"\")\n\n┌──────────────┬────────┬────────┬────────┬────────┬────────┬────────┬────────┬────────┬────────┬────────┐\n│ AccidentYear │   1    │   10   │   2    │   3    │   4    │   5    │   6    │   7    │   8    │   9    │\n│    int64     │ int128 │ int128 │ int128 │ int128 │ int128 │ int128 │ int128 │ int128 │ int128 │ int128 │\n├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n│         1988 │    133 │    614 │    333 │    431 │    570 │    615 │    615 │    615 │    614 │    614 │\n│         1989 │    934 │   NULL │   1746 │   2365 │   2579 │   2763 │   2966 │   2940 │   2978 │   2978 │\n│         1990 │   2030 │   NULL │   4864 │   6880 │   8087 │   8595 │   8743 │   8763 │   8762 │   NULL │\n│         1991 │   4537 │   NULL │  11527 │  15123 │  16656 │  17321 │  18076 │  18308 │   NULL │   NULL │\n│         1992 │   7564 │   NULL │  16061 │  22465 │  25204 │  26517 │  27124 │   NULL │   NULL │   NULL │\n│         1993 │   8343 │   NULL │  19900 │  26732 │  30079 │  31249 │   NULL │   NULL │   NULL │   NULL │\n│         1994 │  12565 │   NULL │  26922 │  33867 │  38338 │   NULL │   NULL │   NULL │   NULL │   NULL │\n│         1995 │  13437 │   NULL │  26012 │  31677 │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │\n│         1996 │  12604 │   NULL │  23446 │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │\n│         1997 │  12292 │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │\n├──────────────┴────────┴────────┴────────┴────────┴────────┴────────┴────────┴────────┴────────┴────────┤\n│ 10 rows                                                                                     11 columns │\n└────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n\n\nUnfortunately, this orders columns as strings so DevelopmentLag 10 comes before DevelopmentLag2. One workaround for this is to left pad (lpad) the DevelopmentLag prior to pivoting so the columns sort as expected.\n\nduckdb.sql(\n    \"\"\"\n    WITH cte\n    AS\n    (\n        SELECT * REPLACE (lpad(CAST(DevelopmentLag AS VARCHAR),2,'0')) AS DevelopmentLag\n        FROM data\n        WHERE GRCODE == 43\n        AND DevelopmentYear &lt;= 1997\n    )\n    PIVOT cte\n    ON DevelopmentLag\n    USING SUM(CumPaidLoss_B)\n    GROUP BY AccidentYear\n    ORDER BY AccidentYear\n    \"\"\"\n)\n\n┌──────────────┬────────┬────────┬────────┬────────┬────────┬────────┬────────┬────────┬────────┬────────┐\n│ AccidentYear │   01   │   02   │   03   │   04   │   05   │   06   │   07   │   08   │   09   │   10   │\n│    int64     │ int128 │ int128 │ int128 │ int128 │ int128 │ int128 │ int128 │ int128 │ int128 │ int128 │\n├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n│         1988 │    133 │    333 │    431 │    570 │    615 │    615 │    615 │    614 │    614 │    614 │\n│         1989 │    934 │   1746 │   2365 │   2579 │   2763 │   2966 │   2940 │   2978 │   2978 │   NULL │\n│         1990 │   2030 │   4864 │   6880 │   8087 │   8595 │   8743 │   8763 │   8762 │   NULL │   NULL │\n│         1991 │   4537 │  11527 │  15123 │  16656 │  17321 │  18076 │  18308 │   NULL │   NULL │   NULL │\n│         1992 │   7564 │  16061 │  22465 │  25204 │  26517 │  27124 │   NULL │   NULL │   NULL │   NULL │\n│         1993 │   8343 │  19900 │  26732 │  30079 │  31249 │   NULL │   NULL │   NULL │   NULL │   NULL │\n│         1994 │  12565 │  26922 │  33867 │  38338 │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │\n│         1995 │  13437 │  26012 │  31677 │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │\n│         1996 │  12604 │  23446 │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │\n│         1997 │  12292 │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │   NULL │\n├──────────────┴────────┴────────┴────────┴────────┴────────┴────────┴────────┴────────┴────────┴────────┤\n│ 10 rows                                                                                     11 columns │\n└────────────────────────────────────────────────────────────────────────────────────────────────────────┘"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "TestPositron",
    "section": "",
    "text": "Modern Tooling to Create Development Triangles\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\nBuild development triangles using Pandas, Polars, and DuckDB\n\n\n\n\n\nNov 15, 2024\n\n\nZachary Luety\n\n\n\n\n\n\n\n\n\n\n\n\nSeasonality in Loss Development Triangles\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\nHow to handle seasonality in loss development triangles\n\n\n\n\n\nNov 11, 2024\n\n\nZachary Luety\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nNov 5, 2024\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  }
]